{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974a023b",
   "metadata": {
    "id": "974a023b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+------+------+\n",
      "| Name|Age|Gender|Salary|DeptId|\n",
      "+-----+---+------+------+------+\n",
      "|James| 34|     M|  3000|     1|\n",
      "| Anna| 28|     F|  4100|     2|\n",
      "|  Lee| 23|     M|  2700|     1|\n",
      "+-----+---+------+------+------+\n",
      "\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Anna| 28|\n",
      "+----+---+\n",
      "\n",
      "+------------------+\n",
      "|       avg(Salary)|\n",
      "+------------------+\n",
      "|3266.6666666666665|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data = [\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "]\n",
    "columns = ['Name', 'Age', 'Gender', 'Salary', 'DeptId']\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.createOrReplaceTempView('employees')\n",
    "spark.sql('SELECT * FROM employees').show()\n",
    "spark.sql('SELECT Name, Age FROM employees WHERE Salary > 3000').show()\n",
    "spark.sql('SELECT AVG(Salary) FROM employees').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc8a9e6",
   "metadata": {
    "id": "4fc8a9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---+\n",
      "|Gender|TotalSalary|Age|\n",
      "+------+-----------+---+\n",
      "|     M|       2700| 23|\n",
      "|     F|       4100| 28|\n",
      "|     M|       3000| 34|\n",
      "+------+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sql('''\n",
    "SELECT Gender, SUM(Salary) as TotalSalary, Age\n",
    "FROM employees\n",
    "GROUP BY Gender, Age\n",
    "ORDER BY Age\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb927310",
   "metadata": {
    "id": "eb927310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+----+\n",
      "| Name|Age|Salary|rank|\n",
      "+-----+---+------+----+\n",
      "|  Lee| 23|  2700|   1|\n",
      "| Anna| 28|  4100|   1|\n",
      "|James| 34|  3000|   1|\n",
      "+-----+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sql('''\n",
    "SELECT Name, Age, Salary, ROW_NUMBER() OVER (PARTITION BY Age ORDER BY Salary DESC) as rank\n",
    "FROM employees\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bfd9fd",
   "metadata": {
    "id": "f1bfd9fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                  (0 + 3) / 4][Stage 2:==============>    (3 + 1) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+-----------+\n",
      "| Name|Age| DeptName|ProjectName|\n",
      "+-----+---+---------+-----------+\n",
      "|  Lee| 23|       HR|  Project A|\n",
      "|James| 34|       HR|  Project A|\n",
      "| Anna| 28|Marketing|  Project B|\n",
      "+-----+---+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Pertemuan9').getOrCreate()\n",
    "\n",
    "# Data setup for complex SQL queries\n",
    "employees = spark.createDataFrame([\n",
    "    ('James', 34, 'M', 3000, 1),\n",
    "    ('Anna', 28, 'F', 4100, 2),\n",
    "    ('Lee', 23, 'M', 2700, 1)\n",
    "], ['Name', 'Age', 'Gender', 'Salary', 'DeptId'])\n",
    "departments = spark.createDataFrame([\n",
    "    (1, 'HR'),\n",
    "    (2, 'Marketing')\n",
    "], ['DeptId', 'DeptName'])\n",
    "projects = spark.createDataFrame([\n",
    "    (1, 'Project A'),\n",
    "    (2, 'Project B')\n",
    "], ['DeptId', 'ProjectName'])\n",
    "employees.createOrReplaceTempView('employees')\n",
    "departments.createOrReplaceTempView('departments')\n",
    "projects.createOrReplaceTempView('projects')\n",
    "\n",
    "# Complex SQL query involving multiple joins and subqueries\n",
    "spark.sql('''\n",
    "SELECT e.Name, e.Age, d.DeptName, p.ProjectName\n",
    "FROM employees e\n",
    "JOIN departments d ON e.DeptId = d.DeptId\n",
    "JOIN projects p ON e.DeptId = p.DeptId\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b379959e-48fc-4d5c-9515-7fe930ee305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "| DeptName|AverageSalary|\n",
      "+---------+-------------+\n",
      "|       HR|       2850.0|\n",
      "|Marketing|       4100.0|\n",
      "+---------+-------------+\n",
      "\n",
      "+-----+---------+------+----+\n",
      "| Name| DeptName|Salary|Rank|\n",
      "+-----+---------+------+----+\n",
      "|James|       HR|  3000|   1|\n",
      "|  Lee|       HR|  2700|   2|\n",
      "| Anna|Marketing|  4100|   1|\n",
      "+-----+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT d.DeptName, AVG(e.Salary) AS AverageSalary\n",
    "FROM employees e\n",
    "JOIN departments d ON e.DeptId = d.DeptId\n",
    "GROUP BY d.DeptName\n",
    "''').show()\n",
    "\n",
    "spark.sql('''\n",
    "SELECT e1.Name, d.DeptName, e1.Salary,\n",
    "       COUNT(e2.Salary) + 1 AS Rank\n",
    "FROM employees e1\n",
    "JOIN departments d ON e1.DeptId = d.DeptId\n",
    "LEFT JOIN employees e2\n",
    "    ON e1.DeptId = e2.DeptId AND e2.Salary > e1.Salary\n",
    "GROUP BY e1.Name, d.DeptName, e1.Salary\n",
    "ORDER BY d.DeptName, Rank\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4104d79-9566-4511-844c-ad9f055686dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+---------+\n",
      "| DeptName| Name|Age|Salary|TrendGaji|\n",
      "+---------+-----+---+------+---------+\n",
      "|       HR|  Lee| 23|  2700|   2700.0|\n",
      "|       HR|James| 34|  3000|   2850.0|\n",
      "|Marketing| Anna| 28|  4100|   4100.0|\n",
      "+---------+-----+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT d.DeptName, e.Name, e.Age, e.Salary,\n",
    "       AVG(e.Salary) OVER (PARTITION BY d.DeptName ORDER BY e.Age) AS TrendGaji\n",
    "FROM employees e\n",
    "JOIN departments d ON e.DeptId = d.DeptId\n",
    "ORDER BY d.DeptName, e.Age\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd314ae9",
   "metadata": {
    "id": "dd314ae9"
   },
   "source": [
    "### 6. Homework\n",
    "- **Tugas 1**: Gunakan Spark SQL untuk mencari total gaji dan jumlah karyawan per departemen. Buat visualisasi perbandingan antar departemen.\n",
    "- **Tugas 2**: Temukan karyawan dengan gaji di atas rata-rata dalam setiap kelompok usia dan visualisasikan data ini dalam bentuk grafik batang atau pie chart.\n",
    "- **Tugas 3**: Buat dataset yang lebih besar (misalnya, 100+ baris) dan lakukan analisis mendalam menggunakan SQL functions seperti `SUM()`, `AVG()`, `COUNT()`, serta `JOIN` antar tabel serta buat visualisasi yang menarik.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
